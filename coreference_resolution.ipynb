{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_g9xQURFU2Y"
      },
      "source": [
        "# Coreference Resolution\n",
        "Coreference resolution is the task of finding all expressions that refer to the same entity in a text. It is an important step for a lot of higher level NLP tasks that involve natural language understanding such as document summarization, question answering, and information extraction. I will be focusing on the following points:\n",
        "* A simple rule-based system that can achieve results that are very hard to beat.\n",
        "* Get acquainted with the trickiness of evaluating coref systems, and the current solutions in the field.\n",
        "* Experiment with two neural approaches for coref to be implemented in PyTorch:\n",
        "  * A feedforward network that only looks at boolean mention-pair features\n",
        "  * A fully-neural architecture with embeddings all the way down"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/aditya-dl/coreference-resolution.git\n",
        "%cd coreference-resolution/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fcs1lR3TFh9u",
        "outputId": "c6723184-3297-476a-c0ea-b9f6faa8229a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'coreference-resolution'...\n",
            "remote: Enumerating objects: 89, done.\u001b[K\n",
            "remote: Counting objects: 100% (89/89), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 89 (delta 2), reused 84 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (89/89), done.\n",
            "/content/coreference-resolution\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T57ok-oVFr68",
        "outputId": "d0b66456-f2db-48de-9f33-a2d363284fcc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nose\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[K     |████████████████████████████████| 154 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting xmltodict\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: xmltodict, nose\n",
            "Successfully installed nose-1.3.7 xmltodict-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "c4uZOze6FU2Z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import nose\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import torch\n",
        "import pickle\n",
        "import sklearn\n",
        "import xmltodict\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from nltk.tag import pos_tag\n",
        "from torch.nn import functional as F\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "scrolled": true,
        "id": "yJbbQ1TCFU2a"
      },
      "outputs": [],
      "source": [
        "from library import coref, coref_rules, coref_features, coref_learning, neural_net, utils\n",
        "\n",
        "# constants for notebook use\n",
        "ETA_0 = 0.01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeY2GAWvFU2b"
      },
      "source": [
        "# Part 1: Exploring the data\n",
        "\n",
        "The core data is in the form of \"markables\", or \"referring expressions\", which refer to token sequences that can participate in coreference relations.\n",
        "\n",
        "Each markable is a namedtuple with five elements:\n",
        "- string: list of tokens\n",
        "- entity: the ground truth assignments\n",
        "- start_token: the index of the first token in the markable with respect to the entire document\n",
        "- end_token: one plus the index of the last token in the markable\n",
        "- tags: POS tags corresponding to the tokens in \"string\"\n",
        "\n",
        "The ```read_data``` function also returns a list of tokens.\n",
        "\n",
        "### Loading the dataset\n",
        "I will explore a dataset of articles from the Wall Street Journal (WSJ) extracted and annotated from the Penn Treebank (PTB)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "id": "AFp6QC4GFU2b"
      },
      "outputs": [],
      "source": [
        "dev_dir = os.path.join('data','wsj','dev')\n",
        "train_dir = os.path.join('data','wsj','train')\n",
        "test_dir = os.path.join('data','wsj','test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "id": "Od-WNoVtFU2b"
      },
      "outputs": [],
      "source": [
        "markables, words = coref.read_data('06_wsj_0051.sty', basedir=train_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy5Svyu2FU2b",
        "outputId": "d6d2b704-c3e9-46ec-94da-105f2e989333"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Markable object: Markable(string=['Fujitsu', 'Ltd.'], entity='set_3082', start_token=0, end_token=2, tags=['NULL', 'NULL'])\n",
            "Words for markable extracted from text: ['Fujitsu', 'Ltd.']\n"
          ]
        }
      ],
      "source": [
        "print('Markable object:', markables[0])\n",
        "print('Words for markable extracted from text:', words[markables[0].start_token:markables[0].end_token])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE6odsVSFU2c",
        "outputId": "299b6850-f6d9-431d-886b-ba2793431272"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Fujitsu',\n",
              " 'Fujitsu',\n",
              " 'Fujitsu',\n",
              " 'Fujitsu',\n",
              " 'Fujitsu',\n",
              " 'Fujitsu',\n",
              " 'Fujitsu',\n",
              " \"Fujitsu , Japan 's No. 1 computer maker\",\n",
              " 'Fujitsu Ltd.',\n",
              " 'It',\n",
              " 'The company',\n",
              " 'The company',\n",
              " 'We',\n",
              " 'his company',\n",
              " 'his company',\n",
              " 'it',\n",
              " 'it',\n",
              " 'it',\n",
              " 'it',\n",
              " 'it',\n",
              " 'it',\n",
              " 'its',\n",
              " 'its',\n",
              " 'the company']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Get all markable \"strings\" associated with a given entity\n",
        "sorted(coref.get_markables_for_entity(markables,'set_3082'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcwKyVVxFU2c",
        "outputId": "8e7e139d-c7ae-4907-88cc-7f74da369ec2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 2, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Showcase a function that takes as input a string, \n",
        "# and returns a list of distances to the most recent ground truth antecedent for every time the (case-insensitive)\n",
        "# input string appears. For example, if the input is \"they\", it should make a list with one element for each time the word \"they\"\n",
        "# appears in the list of markables. Each element should be the distance of the word \"they\" to the nearest previous mention of the entity that\n",
        "# \"they\" references. If the input string is not anaphoric, the distance should be zero. \n",
        "coref.get_distances(markables, 'they')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiGwZptVFU2d"
      },
      "source": [
        "Now let's compare the typical distances for various mention types.\n",
        "\n",
        "You can see the most frequent mention types by using the `Counter` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umjYHkVRFU2d",
        "outputId": "f9567e9b-32d9-4607-adc1-f239a01d4622"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('it', 9), ('Fujitsu', 7), ('Japan', 5), ('they', 5), ('NEC', 4)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "Counter([' '.join(markable.string) for markable in markables]).most_common(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gynqe2lgFU2d",
        "outputId": "1b36338b-a494-49ea-c6fe-a97c307cf622"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[15, 8, 49, 12, 7, 4, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "coref.get_distances(markables, 'Fujitsu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp0ZgLZeFU2d",
        "outputId": "c566106c-6038-4b1c-c7c7-9ba2c45c982a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 4, 6]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "coref.get_distances(markables, 'the company')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysfQFLhBFU2d",
        "outputId": "8f5da9f6-58f7-4a35-9bab-c322fcf1481f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 2, 1, 6, 1, 6, 2, 6, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "coref.get_distances(markables, 'it') # there are 10 because our counter was case-sensitive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Zfw6BXfFU2e"
      },
      "source": [
        "# 2. Rule-based coreference resolution\n",
        "\n",
        "I have written a simple coreference classifier, which predicts that each markable is linked to the most recent antecedent which is an exact string match.\n",
        "\n",
        "The code block below applies this method to the dev set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "collapsed": true,
        "id": "mMFQbljgFU2e"
      },
      "outputs": [],
      "source": [
        "exact_matcher = coref_rules.make_resolver(coref_rules.exact_match)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_bZ0XK9FU2e"
      },
      "source": [
        "The code above has two pieces:\n",
        "\n",
        "- ```coref_rules.exact_match()``` is a function that takes two markables, and returns `True` iff they are an exact (case-insensitive) string match\n",
        "- ```make_resolver()``` is a function that takes a matching function, and returns a function that computes an antecedent list for a list of markables.\n",
        "\n",
        "Let's run it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HX9qNQeFU2f",
        "outputId": "11cd9a7c-e711-4411-eea5-60507b8cf1a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 21, 28, 29, 30, 31, 32, 33, 34, 35, 27, 8, 38, 39, 40, 41, 42, 20, 44, 45, 46, 47, 48, 49]\n"
          ]
        }
      ],
      "source": [
        "ant_exact = exact_matcher(markables)\n",
        "print(ant_exact[:50])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R11diF4FU2g"
      },
      "source": [
        "The output is a list of antecedent numbers, $c_i$. \n",
        "When $c_i = i$, the markable $i$ has no antecedent: it is the first mention of its entity. In this case, all first 20 mentions are new and don't have antecedents. \n",
        "\n",
        "We can test whether these predictions are correct by comparing against the key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h025ex1gFU2g",
        "outputId": "f8c53995-6d8c-46a5-9176-79f993a68863"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 1, 0, 6, 7, 8, 9, 10, 11, 12, 6, 14, 15, 16, 13, 15, 19, 5, 20, 8, 23, 24, 21, 24, 25, 28, 28, 30, 27, 32, 33, 11, 31, 34, 22, 38, 39, 38, 36, 42, 35, 44, 45, 46, 47, 48, 49, 50, 18, 51, 53, 54, 17, 56, 52, 58, 32, 60, 60, 7, 63, 43, 65, 4, 67, 66, 69, 68, 64, 72, 62, 70, 75, 41, 77, 76, 79, 80, 81, 59, 83, 84, 85, 86, 87, 88, 89, 82, 91, 92, 93, 94, 95, 88, 97, 98, 55, 100, 101, 102, 103, 104, 73, 106, 107, 108, 108, 110, 90, 84, 109, 114, 115, 116, 112, 118, 119, 71, 78, 122, 123, 74, 122, 126, 96, 37, 129, 130, 131, 120, 133, 134, 131, 136, 135, 138, 132, 134, 141, 142, 139, 143, 145, 146, 147, 148, 149, 144, 151, 150, 153, 154, 155, 156, 157, 152, 128, 160, 161, 158, 162, 163, 165, 137, 147, 168, 168, 164, 171, 170, 57, 121, 173, 176, 165, 124, 179, 177, 178, 182, 142, 184, 185, 184, 180, 159, 189, 190, 111, 192, 193]\n"
          ]
        }
      ],
      "source": [
        "ant_true = coref.get_true_antecedents(markables)\n",
        "print(ant_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVGNrpFDFU2g",
        "outputId": "02e06adf-19f1-4d7a-b120-65fa21830903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correct: 128\taccuracy: 0.660\n"
          ]
        }
      ],
      "source": [
        "num_correct = sum([c_true == c_predict for c_true, c_predict in zip(ant_true, ant_exact)])\n",
        "acc = num_correct / len(markables)\n",
        "print(f'correct: {num_correct}\\taccuracy: {acc:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9E9NI7trFU2g"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "Coreference can be evaluated in terms of recall, precision, and F-measure. Here is how we will define these terms:\n",
        "\n",
        "- **True positive**: The system predicts $\\hat{c}_i < i$, and $\\hat{c}_i$ and $i$ are references to the same entity.\n",
        "- **False positive**: The system predicts $\\hat{c}_i < i$, but $\\hat{c}_i$ and $i$ are not references to the same entity.\n",
        "- **False negative**: There exists some $c_i < i$ such that $c_i$ and $i$ are references to the same entity, but the system predicts either $\\hat{c}_i = i$, or some $\\hat{c}_i$ which is not really a reference to the same entity that $i$ references.\n",
        "- Recall = $\\frac{tp}{tp + fn}$\n",
        "- Precision = $\\frac{tp}{tp + fp}$\n",
        "- F-measure = $\\frac{2RP}{R+P}$\n",
        "\n",
        "A couple of things to notice here:\n",
        "\n",
        "- There is no reward for correctly identifying a markable as non-anaphoric (not having any antecedent), but you do avoid committing a false positive by doing this.\n",
        "- You cannot compute the evaluation by directly matching the predicted antecedents to the true antecedents. Suppose the truth is $a \\leftarrow b, b \\leftarrow c$, but the system predicts $a \\leftarrow b, a \\leftarrow c$: the system should receive two true positives, since $a$ and $c$ are references to the same entity in the ground truth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrSSqeKuFU2h",
        "outputId": "3908daf7-70f7-4f34-9cb9-cac3c3038875"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5231\t0.4096\t0.7234\n"
          ]
        }
      ],
      "source": [
        "f,r,p = coref.evaluate_f(exact_matcher, markables)\n",
        "print(f'{f:.4f}\\t{r:.4f}\\t{p:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "collapsed": true,
        "scrolled": false,
        "id": "MxOXZb-WFU2h"
      },
      "outputs": [],
      "source": [
        "all_markables, all_words = coref.read_dataset(train_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEq9yUMUFU2h",
        "outputId": "2eb6fc59-1bdd-4586-9c1c-29d640a11a08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F: 0.5452\tR: 0.4130\tP:0.8018\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.545176110260337, 0.41299303944315546, 0.8018018018018018)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "coref.eval_on_dataset(exact_matcher, all_markables)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr6oGYkoFU2h"
      },
      "source": [
        "Before optimizing on this simple F-measure (sometimes called F1) and its components, one should be aware that in the real world coreference is evaluated over three other metrics, namely $B^3$, **`CEAF`**, and **`MUC`**. You can read more about them [here](http://www.anthology.aclweb.org/W/W10/W10-4305.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "collapsed": true,
        "id": "6Z_do_gHFU2h"
      },
      "outputs": [],
      "source": [
        "def coref_metrics(matcher, dataset):\n",
        "    ants = [matcher(m) for m in dataset]\n",
        "    b3, ceaf, muc = coref.evaluate_bcm(dataset, ants)\n",
        "    avg_f1 = np.average([b3, ceaf, muc])\n",
        "    print(f'B-Cubed: {b3:.4f}\\tCEAF: {ceaf:.4f}\\tMUC: {muc:.4f}\\tAverage: {avg_f1:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dy03dfZFU2h",
        "outputId": "bf5f3d9a-e4a6-4f55-cc1c-3d638eb22f0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B-Cubed: 0.5756\tCEAF: 0.4551\tMUC: 0.5605\tAverage: 0.5304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/coreference-resolution/library/utils.py:168: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  \"scipy.optimize.linear_sum_assignment instead.\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "coref_metrics(exact_matcher, all_markables); #\"Average\" is the commonly used main metric in state-of-the-art systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlFU4ZwPFU2h"
      },
      "source": [
        "The reasons for having multiple measures for coref evaluation is manyfold. One of them has to do with the pre-resolution task of *identifying markables*. Since we're only working with pre-extracted markables, that needn't worry us.\n",
        "\n",
        "The other reason is that different perspectives on coreference matching are equally plausible - we can focus on single correct predictions, or finding the correct clusters for each entity , for example. Each of these is \"gameable\" by different trivial classifiers.\n",
        "\n",
        "To witness this problem, I am implementing `coref_rules.singleton_matcher()`, which produces an assignment where each markable has its own entity, and `coref_rules.full_cluster_matcher()`, which assigns all markables to the same entity. Running the metrics against them will demonstrate the problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJXqw3XZFU2h",
        "outputId": "aa57be3a-7bfd-4c17-f7ce-4bea61d92d27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B-Cubed: 0.3411\tCEAF: 0.0012\tMUC: 0.0000\tAverage: 0.1141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/coreference-resolution/library/utils.py:168: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  \"scipy.optimize.linear_sum_assignment instead.\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "singleton_resolver = coref_rules.make_resolver(coref_rules.singleton_matcher)\n",
        "coref_metrics(singleton_resolver, all_markables);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CyH18UYFU2h"
      },
      "source": [
        "MUC has an inherent problem evaluating singleton entities. $B^3$, on the other hand, is extra-generous with them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRiWXgRVFU2h",
        "outputId": "e3c98c85-b9ca-4740-ac52-f919eff5f76c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B-Cubed: 0.0739\tCEAF: 0.0304\tMUC: 0.5552\tAverage: 0.2199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/coreference-resolution/library/utils.py:168: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  \"scipy.optimize.linear_sum_assignment instead.\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "full_cluster_resolver = coref_rules.make_resolver(coref_rules.full_cluster_matcher)\n",
        "coref_metrics(full_cluster_resolver, all_markables);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnkuxivaFU2i"
      },
      "source": [
        "In this case MUC, which is focused on detecting incompatible clusters, is fairly comfortable with the fact that there's only one predicted cluster.\n",
        "CEAF, a metric which gives low precision very easily, is difficult to score high on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UchrsBPYFU2i"
      },
      "source": [
        "## Increasing precision\n",
        "\n",
        "The `exact_match()` function matches everything, including pronouns. This can lead to mistakes:\n",
        "\n",
        "\"Umashanthi ate pizza until she was full. Parvati kept eating until she had a stomach ache.\"\n",
        "\n",
        "In this example, both pronouns likely refer to the names that immediately precede them, and not to each other.\n",
        "\n",
        "The file `coref_rules.py` contains the signature for a function `exact_match_no_pronoun()`, which solves this problem by only predicting matches between markables that are not pronouns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "N6bBCa_YFU2i"
      },
      "outputs": [],
      "source": [
        "no_pro_matcher = coref_rules.make_resolver(coref_rules.exact_match_no_pronouns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upP7rkPKFU2i",
        "outputId": "827dfaac-8faa-496d-c864-2451c36c017a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F: 0.4551\tR: 0.3028\tP:0.9158\n"
          ]
        }
      ],
      "source": [
        "f,r,p = coref.eval_on_dataset(no_pro_matcher,all_markables);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Q99odevFU2i",
        "outputId": "ef804926-693c-42c2-85bd-cc8c3578dd70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B-Cubed: 0.5678\tCEAF: 0.4269\tMUC: 0.4568\tAverage: 0.4839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/coreference-resolution/library/utils.py:168: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  \"scipy.optimize.linear_sum_assignment instead.\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "coref_metrics(no_pro_matcher, all_markables);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5n4YwDwFU2i"
      },
      "source": [
        "Precision has increased, but recall decreased, dragging down the overall F-measure as well as our favorite metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3nM0NDfFU2i"
      },
      "source": [
        "## Increasing recall\n",
        "\n",
        "Our current matcher is very conservative. Let's try to increase recall. One solution is match on the **head word** of each markable. \n",
        "\n",
        "In a CFG parse, the head word is defined by a set of rules: for example, the head of a determiner-noun construction is the noun. In a dependency parse, the head word would be the root of the subtree governing the markable span. But this assumes that the markables correspond to syntactic constituents or dependency subtrees. This is not guaranteed to be true - particularly when there are parsing errors.\n",
        "\n",
        "Let's start with a much simpler head-finding heuristic: simply select the *last word* in the markable. This handles many cases - but as we will see, not all. The function `match_last_token()` in ```coref_rules.py``` does this. This function matches all cases where the final tokens match."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "collapsed": true,
        "id": "962vUjdBFU2i"
      },
      "outputs": [],
      "source": [
        "last_tok_matcher = coref_rules.make_resolver(coref_rules.match_last_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKJf3zp8FU2i",
        "outputId": "7b373dd2-aa11-4733-fbd9-c429038d3992"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F: 0.3994\tR: 0.4385\tP:0.3666\n"
          ]
        }
      ],
      "source": [
        "coref.eval_on_dataset(last_tok_matcher,all_markables);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mt-7EXPFFU2i"
      },
      "source": [
        "Recall is up, but precision is back down. To try to increase precision, let's add one more rule: two markables cannot coref if their spans overlap. This can happen with nested mentions, such as \"(the president (of the United States))\". Under our last-token rule, these two mentions would co-refer, but logically, overlapping markables cannot refer to the same entity. \n",
        "\n",
        "The function `match_last_token_no_overlap()` matches any two markables that share the same last token, unless their spans overlap. I am using the `start_token` and `end_token` members of each markable to determine whether they overlap. the final tokens match."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-n6qA_3PFU2i",
        "outputId": "2687bab5-3add-49df-c2bf-97bd2e2ae83e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F: 0.4911\tR: 0.4965\tP:0.4858\n"
          ]
        }
      ],
      "source": [
        "mltno_matcher = coref_rules.make_resolver(coref_rules.match_last_token_no_overlap)\n",
        "coref.eval_on_dataset(mltno_matcher,all_markables);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vObEsQnDFU2j"
      },
      "source": [
        "Both recall and precision increase. Why would recall increase? The restriction does not create any new coreference links, but it changes some incorrect links to correct links. This increases the number of true positives and reduces the number of false negatives."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_eKptM7FU2j",
        "outputId": "8a4644bf-f14c-4227-8066-dc184b15bcfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B-Cubed: 0.5571\tCEAF: 0.4610\tMUC: 0.5473\tAverage: 0.5218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/coreference-resolution/library/utils.py:168: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  \"scipy.optimize.linear_sum_assignment instead.\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "coref_metrics(mltno_matcher, all_markables);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1O1X5l3FU2j"
      },
      "source": [
        "Almost back to the results from the exact matcher."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkRvjUaPFU2j"
      },
      "source": [
        "## Error analysis\n",
        "\n",
        "To see whether we can do even better, let's try some error analysis on a specific file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "collapsed": true,
        "id": "bgWmo3m9FU2j"
      },
      "outputs": [],
      "source": [
        "# predicted antecedent series\n",
        "markables_17, _ = coref.read_data('17_wsj_0072.sty',basedir=train_dir)\n",
        "ant = coref_rules.make_resolver(coref_rules.match_last_token_no_overlap)(markables_17)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "collapsed": true,
        "id": "RdDuwy3gFU2j"
      },
      "outputs": [],
      "source": [
        "# let's look at large entities\n",
        "m2e, e2m = coref.markables_to_entities(markables_17,ant)\n",
        "big_entities = [ent for ent, vals in e2m.items() if len(vals) > 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smHoLguQFU2j",
        "outputId": "473da208-117e-4382-8ba6-982a3463cf62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity 8: 11 mentions\n",
            "['Fed', 'Kansas City Fed', 'the Fed', 'the Fed', 'The Fed', 'The report from the Fed', 'the Fed', 'The Philadelphia Fed', 'Fed', 'Fed', 'regional Fed']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for entity in big_entities:\n",
        "    print(f'Entity {entity}: {len(e2m[entity])} mentions')\n",
        "    print([' '.join(markables_17[idx].string) for idx in e2m[entity]])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jtiJzy9FU2j"
      },
      "source": [
        "## Incorporating parts of speech\n",
        "\n",
        "One clear mistake is that we are matching ''Kansas City Fed'' to ''The Philadelphia Fed'' and other ''Fed''s. The last token heuristic is the culprit: in this case, the first token is a key disambiguator. Let's try a more syntactically-motivated approach. \n",
        "\n",
        "Instead of matching the last token (low precision) or matching on all tokens (low recall), let's try matching on all *content* words. Let's start by including only the following grammatical categories:\n",
        "\n",
        "- Nouns (proper, common, singular, plural)\n",
        "- Pronouns (including possessive)\n",
        "- Adjectives (including comparative and superlative)\n",
        "- Cardinal numbers\n",
        "\n",
        "To get these categories, we can call `read_dataset()` again with the optional `tagger` argument, a part of speech tagger. We'll use NLTK for this project, which has a structured perceptron tagger on the [PTB tagset](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "scrolled": true,
        "id": "QoPJVQLtFU2j"
      },
      "outputs": [],
      "source": [
        "all_markables, _ = coref.read_dataset(train_dir, tagger=pos_tag)\n",
        "all_markables_dev, all_words_dev = coref.read_dataset(dev_dir, tagger=pos_tag)\n",
        "all_markables_te, all_words_test = coref.read_dataset(test_dir, tagger=pos_tag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4L_ZwMRFU2j",
        "outputId": "9fb207ab-6bd1-4ddc-e0ed-f43ebf2135c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Markable(string=['a', 'trade', 'deficit', 'of', '$', '101', 'million'], entity='set_972', start_token=3, end_token=10, tags=['DT', 'NN', 'NN', 'IN', '$', 'CD', 'CD'])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "all_markables[1][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-c0Wdgd3FU2j"
      },
      "source": [
        "As you can see, the markables now have the `tags` member populated with the part-of-speech tags for each token in the `string` field.\n",
        "\n",
        "We implement a new matcher, `coref_rules.match_on_content()`. This should match $m_a$ and $m_i$ iff all content words are identical. It should also enforce the \"no overlap\" restriction defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu4f4OLGFU2j",
        "outputId": "cf6014f5-395b-4387-d392-91e238192cd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F: 0.5565\tR: 0.4374\tP:0.7647\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5564575645756457, 0.43735498839907194, 0.7647058823529411)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "content_matcher = coref_rules.make_resolver(coref_rules.match_on_content)\n",
        "coref.eval_on_dataset(content_matcher, all_markables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvPpFuGGFU2j",
        "outputId": "d292bb69-cf8d-4cfa-dbdd-de5975d47b9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B-Cubed: 0.5872\tCEAF: 0.4725\tMUC: 0.5727\tAverage: 0.5441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/coreference-resolution/library/utils.py:168: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  \"scipy.optimize.linear_sum_assignment instead.\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "coref_metrics(content_matcher, all_markables)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEPKwddLFU2j"
      },
      "source": [
        "Finally getting some headway on those metrics!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "scrolled": true,
        "id": "OJWkHpoBFU2k"
      },
      "outputs": [],
      "source": [
        "# run once, then remove/comment out cell after dir is created\n",
        "!mkdir predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "collapsed": true,
        "id": "kbKwL_v3FU2k"
      },
      "outputs": [],
      "source": [
        "coref.write_predictions(coref_rules.make_resolver(coref_rules.match_on_content),\n",
        "                        all_markables_dev, 'predictions/rules-dev.preds')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AH3wj_HCFU2k",
        "outputId": "420f4e86-6253-4930-b17e-0e76e7cea613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F: 0.5463\tR: 0.3960\tP:0.8806\n"
          ]
        }
      ],
      "source": [
        "f,r,p = coref.eval_predictions('predictions/rules-dev.preds',all_markables_dev);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSASUMAqFU2k",
        "outputId": "ecb1636f-0488-4694-ff83-9c4446d94dd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B-Cubed: 0.5768\tCEAF: 0.4045\tMUC: 0.5463\tAverage: 0.5092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/coreference-resolution/library/utils.py:168: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  \"scipy.optimize.linear_sum_assignment instead.\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "coref_metrics(content_matcher, all_markables_dev);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "collapsed": true,
        "id": "UXilCP1HFU2k"
      },
      "outputs": [],
      "source": [
        "coref.write_predictions(coref_rules.make_resolver(coref_rules.match_on_content), all_markables_te, \n",
        "                        'predictions/rules-test.preds')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUYR2_zSFU2k"
      },
      "source": [
        "# Part 3: Machine learning for coreference resolution\n",
        "\n",
        "We will now implement coreference resolution using the mention-ranking model. Let's start by implementing some features.\n",
        "\n",
        "We are implementing `coref_features.minimal_features`, using the rules we wrote from `coref_rules.` This should be a function that takes a list of markables, and indices for two mentions, and returns a dict with features and counts. Include the following features:\n",
        "\n",
        "- `exact-match`\n",
        "- `last-token-match`\n",
        "- `content-match`\n",
        "- `crossover`: value of 1 iff the mentions overlap\n",
        "- `new-entity`: value of 1 iff i=j\n",
        "\n",
        "For the first four features, I call the code from coref_rules directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb9dgN3rFU2k",
        "outputId": "275625ce-bba4-4694-be79-13ea05f41eda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Markable(string=['South', 'Korea'], entity='set_971', start_token=0, end_token=2, tags=['NNP', 'NNP'])\n",
            "1 Markable(string=['a', 'trade', 'deficit', 'of', '$', '101', 'million'], entity='set_972', start_token=3, end_token=10, tags=['DT', 'NN', 'NN', 'IN', '$', 'CD', 'CD'])\n",
            "2 Markable(string=['October'], entity='set_973', start_token=11, end_token=12, tags=['NNP'])\n",
            "3 Markable(string=['the', 'country', \"'s\", 'economic', 'sluggishness'], entity='set_974', start_token=14, end_token=19, tags=['DT', 'NN', 'POS', 'JJ', 'NN'])\n",
            "4 Markable(string=['country'], entity='set_971', start_token=15, end_token=16, tags=['NN'])\n",
            "5 Markable(string=['government', 'figures'], entity='set_975', start_token=22, end_token=24, tags=['NN', 'NNS'])\n",
            "6 Markable(string=['Wednesday'], entity='set_976', start_token=25, end_token=26, tags=['NNP'])\n",
            "7 Markable(string=['Preliminary', 'tallies'], entity='set_977', start_token=27, end_token=29, tags=['JJ', 'NNS'])\n",
            "8 Markable(string=['the', 'Trade', 'and', 'Industry', 'Ministry'], entity='set_978', start_token=30, end_token=35, tags=['DT', 'NNP', 'CC', 'NNP', 'NNP'])\n",
            "9 Markable(string=['another', 'trade', 'deficit', 'the', 'fifth', 'monthly', 'setback', 'this', 'year'], entity='set_979', start_token=36, end_token=48, tags=['DT', 'NN', 'NN', 'IN', 'NNP', ',', 'DT', 'JJ', 'JJ', 'NN', 'DT', 'NN'])\n",
            "10 Markable(string=['October'], entity='set_973', start_token=40, end_token=41, tags=['NNP'])\n",
            "11 Markable(string=['this', 'year'], entity='set_980', start_token=46, end_token=48, tags=['DT', 'NN'])\n",
            "12 Markable(string=['a', 'cloud'], entity='set_981', start_token=50, end_token=52, tags=['DT', 'NN'])\n",
            "13 Markable(string=['South', 'Korea'], entity='set_971', start_token=53, end_token=55, tags=['NNP', 'NNP'])\n",
            "14 Markable(string=['South', 'Korea', \"'s\", 'export-oriented', 'economy'], entity='set_982', start_token=53, end_token=58, tags=['NNP', 'NNP', 'POS', 'JJ', 'NN'])\n"
          ]
        }
      ],
      "source": [
        "min_features = ['exact-match', 'last-token-match', 'content-match', 'crossover', 'new-entity']\n",
        "for i, markable in enumerate(all_markables[1][:15]):\n",
        "    print(i, markable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeSeTlTIFU2k",
        "outputId": "b87ecdd5-c4ec-422b-8147-638e1d13b46a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<class 'float'>, {})\n",
            "defaultdict(<class 'float'>, {'exact-match': 1, 'last-token-match': 1, 'content-match': 1})\n",
            "defaultdict(<class 'float'>, {'crossover': 1})\n",
            "defaultdict(<class 'float'>, {'new-entity': 1})\n",
            "defaultdict(<class 'float'>, {'exact-match': 1, 'last-token-match': 1, 'content-match': 1})\n"
          ]
        }
      ],
      "source": [
        "print(coref_features.minimal_features(all_markables[1],0,1))\n",
        "print(coref_features.minimal_features(all_markables[1],0,13))\n",
        "print(coref_features.minimal_features(all_markables[1],13,14))\n",
        "print(coref_features.minimal_features(all_markables[1],6,6))\n",
        "print(coref_features.minimal_features(all_markables[1],2,10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaWhaLdHFU2k"
      },
      "source": [
        "We will now use these features in a simple feedforward neural net. Using pytorch, I implement the `coref_learning.FFCoref` which will be composed of two linear layers separated by a tanh nonlinearity, producing a score for each possible antecedent.\n",
        "\n",
        "Later we will use this scoring function to select the most probable antecendent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "collapsed": true,
        "id": "yAvMCoxPFU2k"
      },
      "outputs": [],
      "source": [
        "COREF_FF_HIDDEN = 5 # dimension for hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1BsK-s5FU2k",
        "outputId": "9bf817e8-fa4e-4341-cc90-ddd0b7af1934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.1148], grad_fn=<AddBackward0>)\n",
            "tensor([-0.3763], grad_fn=<AddBackward0>)\n",
            "tensor([-0.3763], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(1984) # DO NOT CHANGE\n",
        "coref_ff = coref_learning.FFCoref(min_features, COREF_FF_HIDDEN)\n",
        "\n",
        "# scores for single mention pairs, no backprop\n",
        "print(coref_ff(coref_features.minimal_features(all_markables[1],0,1)))\n",
        "print(coref_ff(coref_features.minimal_features(all_markables[1],0,13)))\n",
        "print(coref_ff(coref_features.minimal_features(all_markables[1],2,10)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFol3u2DFU2k"
      },
      "source": [
        "Given a markable and all its possible antecedents, we now wish to feed all the scores into a softmax layer and attempt the highest possible sum of likelihoods for antecedents representing the correct entity. `FFCoref.score_instance()` does this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSDsVV0bFU2k",
        "outputId": "cbc553f7-2aac-4681-cd2b-cce32f3cabd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.3763, -0.1148, -0.1148, -0.1148, -0.1148, -0.1148, -0.1148, -0.1148,\n",
            "         -0.1148, -0.1148, -0.1148, -0.1148, -0.1148, -0.0424]],\n",
            "       grad_fn=<CopySlices>)\n"
          ]
        }
      ],
      "source": [
        "i_scores = coref_ff.score_instance(all_markables[1], coref_features.minimal_features, 13)\n",
        "print(i_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGZYX_BjFU2k"
      },
      "source": [
        "In inference time, all we need is to use the above function and report the antecedent for each markable. In training time, we will use an objective based on the **hinge margin-loss** function. Our variant will require the highest-scoring false candidate (according to the true entity annotations) to score lower than the highest-scoring true candidate *by a margin*:\n",
        "\n",
        "$$L_{m_i} = \\{ \\text{max}_{a:m_a\\notin A(m_i)} s(m_i,m_a) + M - \\text{max}_{a:m_a\\in A(m_i)} s(m_i,m_a) \\}_{+}$$\n",
        "\n",
        "Where $s$ is the score from the previous deliverable, $A(m)$ denotes the set of true antecedents for $m$, $M$ is our margin, and the $+$ subscript indicates that negative values are replaced by $0$ (since this is a hinge loss).\n",
        "\n",
        "We implement the helper function `FFCoref.instance_top_scores()` which supplies the arguments for this loss function.\n",
        "**Note** the special cases where:\n",
        "- Only true candidates exist (we're in the first cluster) - the trainer will have to skip these. Return `None`s.\n",
        "- Only false candidates exist - this actually means we're in a new cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdbKHOzkFU2l"
      },
      "outputs": [],
      "source": [
        "best_true_score, best_false_score = coref_ff.instance_top_scores(all_markables[1], coref_features.minimal_features, 13, 4)\n",
        "print(torch.cat([best_true_score, best_false_score], 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iuaz2M27FU2l"
      },
      "source": [
        "Looks like we're ready to train our classifier!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJMDJDXIFU2l",
        "outputId": "243e5f0c-d2f8-4497-b25d-75c71c7e9fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss = 0.862643513347134\n",
            "Loss = 0.6986558071670488\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(1984)\n",
        "coref_ff = coref_learning.FFCoref(min_features, COREF_FF_HIDDEN)\n",
        "optimizer = optim.SGD(coref_ff.parameters(), lr=ETA_0)\n",
        "coref_learning.train(coref_ff, optimizer, all_markables, coref_features.minimal_features, margin=1.0, epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvhkwIPdFU2l",
        "outputId": "c681ede9-b48d-4dc1-8c53-4d0d8fef1dbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F: 0.5310\tR: 0.4176\tP:0.7287\n"
          ]
        }
      ],
      "source": [
        "# training set results\n",
        "coref_learning.evaluate(coref_ff, all_markables, coref_features.minimal_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_YjebJJFU2l",
        "outputId": "64407465-3c66-4bac-9d78-527e7e6c01ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F: 0.5505\tR: 0.4027\tP:0.8696\n"
          ]
        }
      ],
      "source": [
        "# dev set\n",
        "coref_learning.evaluate(coref_ff, all_markables_dev, coref_features.minimal_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMvO1xWkFU2l",
        "outputId": "c2069420-5f52-4a20-c391-24e19924a8f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B-Cubed: 0.5869\tCEAF: 0.4718\tMUC: 0.5723\tAverage: 0.5436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/coreference-resolution/library/utils.py:168: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  \"scipy.optimize.linear_sum_assignment instead.\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# standard metrics on training set\n",
        "ff_matcher = coref_learning.make_resolver(coref_features.minimal_features, coref_ff)\n",
        "coref_metrics(ff_matcher, all_markables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0DUc3wXFU2l",
        "outputId": "60828ea8-b33f-4992-bed0-d718cd7a9650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B-Cubed: 0.0228\tCEAF: 0.0071\tMUC: 0.3797\tAverage: 0.1365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/coreference-resolution/library/utils.py:168: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  \"scipy.optimize.linear_sum_assignment instead.\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "#test set, students can't run\n",
        "coref_metrics(ff_matcher, all_markables_te)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tuj2iz8VFU2l"
      },
      "source": [
        "We can add more features to try and better capture relations between markables.\n",
        "\n",
        "I implement distance features in `coref_features.distance_features()`, measuring the mention distance and the token distance. Specifically:\n",
        "\n",
        "- **Mention distance** is number of intervening mentions between i and j, $i-j$.\n",
        "- **Token distance** is number of tokens between the start of i and the end of j.\n",
        "\n",
        "These should be binary features, up to a maximum distance of 10 for tokens / 5 for mentions, with the final feature indicating distance of 10/5 and above, respectively. The desired behavior is shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnAiAPscFU2l",
        "outputId": "129dda9d-2d79-4c7a-e26b-bd73d606114c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Markable(string=['South', 'Korea'], entity='set_971', start_token=0, end_token=2, tags=['NNP', 'NNP'])\n",
            "1 Markable(string=['a', 'trade', 'deficit', 'of', '$', '101', 'million'], entity='set_972', start_token=3, end_token=10, tags=['DT', 'NN', 'NN', 'IN', '$', 'CD', 'CD'])\n",
            "2 Markable(string=['October'], entity='set_973', start_token=11, end_token=12, tags=['NNP'])\n",
            "3 Markable(string=['the', 'country', \"'s\", 'economic', 'sluggishness'], entity='set_974', start_token=14, end_token=19, tags=['DT', 'NN', 'POS', 'JJ', 'NN'])\n"
          ]
        }
      ],
      "source": [
        "for i, markable_i in enumerate(all_markables[1][:4]):\n",
        "    print(i, markable_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4ZeKNXmFU2l",
        "outputId": "f8e69fc9-7250-4e97-9cad-25621255f8c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<class 'float'>, {})\n",
            "defaultdict(<class 'float'>, {'mention-distance-1': 1, 'token-distance-1': 1})\n",
            "defaultdict(<class 'float'>, {'mention-distance-2': 1, 'token-distance-9': 1})\n",
            "defaultdict(<class 'float'>, {'mention-distance-2': 1, 'token-distance-4': 1})\n",
            "defaultdict(<class 'float'>, {'mention-distance-5': 1, 'token-distance-10': 1})\n"
          ]
        }
      ],
      "source": [
        "print(coref_features.distance_features(all_markables[1],0,0))\n",
        "print(coref_features.distance_features(all_markables[1],0,1))\n",
        "print(coref_features.distance_features(all_markables[1],0,2))\n",
        "print(coref_features.distance_features(all_markables[1],1,3))\n",
        "print(coref_features.distance_features(all_markables[1],0,30))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRURILjxFU2l"
      },
      "source": [
        "We implement `coref_features.make_feature_union()`, which should take a list of feature functions, and return a function that computes the union of all features in the list. You can assume the feature functions don't use the same name for any feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "collapsed": true,
        "id": "_IqPUQxxFU2l"
      },
      "outputs": [],
      "source": [
        "joint_feats = coref_features.make_feature_union([coref_features.minimal_features,\n",
        "                                                 coref_features.distance_features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrjzybr2FU2l",
        "outputId": "761060d3-3868-4a65-e977-446d54b1983c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<class 'float'>, {'mention-distance-2': 1, 'token-distance-4': 1})\n",
            "defaultdict(<class 'float'>, {'mention-distance-3': 1, 'token-distance-10': 1})\n",
            "defaultdict(<class 'float'>, {'mention-distance-5': 1, 'token-distance-10': 1})\n",
            "defaultdict(<class 'float'>, {'new-entity': 1})\n"
          ]
        }
      ],
      "source": [
        "print(joint_feats(all_markables[1],1,3))\n",
        "print(joint_feats(all_markables[1],0,3))\n",
        "print(joint_feats(all_markables[1],0,7))\n",
        "print(joint_feats(all_markables[1],10,10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "collapsed": true,
        "id": "ZzqVYEQ1FU2l"
      },
      "outputs": [],
      "source": [
        "min_features_and_distances = min_features\\\n",
        "                                   + [f'mention-distance-{i}' for i in range(1,6)]\\\n",
        "                                   + [f'token-distance-{i}' for i in range(1,11)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Veecx7TwFU2l",
        "outputId": "adc751f8-45c3-40fd-9f08-9529dae1e9fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss = 0.7608438846118514\n",
            "Loss = 0.7099070981127558\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(1984)\n",
        "coref_ff_w_distances = coref_learning.FFCoref(min_features_and_distances, 50) # we need more hidden units now\n",
        "optimizer = optim.SGD(coref_ff_w_distances.parameters(), lr=ETA_0)\n",
        "coref_learning.train(coref_ff_w_distances, optimizer, all_markables, joint_feats, epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWNDBW05FU2m",
        "outputId": "a53448b1-44b9-4b60-d41b-82a96b8ef357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F: 0.4932\tR: 0.5023\tP:0.4843\n"
          ]
        }
      ],
      "source": [
        "coref_learning.evaluate(coref_ff_w_distances, all_markables, joint_feats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iatmOgieFU2m",
        "outputId": "4580972d-6028-414d-99ef-54427438a87c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B-Cubed: 0.5579\tCEAF: 0.4671\tMUC: 0.5421\tAverage: 0.5224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/coreference-resolution/library/utils.py:168: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  \"scipy.optimize.linear_sum_assignment instead.\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "ff_w_dist_matcher = coref_learning.make_resolver(joint_feats, coref_ff_w_distances)\n",
        "coref_metrics(ff_w_dist_matcher, all_markables);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66VJyXcCFU2m"
      },
      "source": [
        "Note that our basic F metric got slightly better, while the average standard metric got slightly worse due to reduced MUC and CEAF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKEUe2czFU2m",
        "outputId": "c2fbe3b8-9a8e-41fc-fe12-4e3ff816b57a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F: 0.5088\tR: 0.4832\tP:0.5373\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5088339222614842, 0.48322147651006714, 0.5373134328358209)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "coref.write_predictions(ff_w_dist_matcher,\n",
        "                        all_markables_dev,\n",
        "                        'predictions/ff-dev.preds')\n",
        "coref.eval_predictions('predictions/ff-dev.preds', all_markables_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QF-oCQa1FU2m",
        "outputId": "d897f837-88ad-4238-e325-a65dd0bdfe17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B-Cubed: 0.5702\tCEAF: 0.4859\tMUC: 0.5442\tAverage: 0.5334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/coreference-resolution/library/utils.py:168: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  \"scipy.optimize.linear_sum_assignment instead.\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "coref_metrics(ff_w_dist_matcher, all_markables_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "collapsed": true,
        "id": "CukXTs9oFU2m"
      },
      "outputs": [],
      "source": [
        "coref.write_predictions(ff_w_dist_matcher,\n",
        "                        all_markables_te,\n",
        "                        'predictions/ff-test.preds')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11PQLcGdFU2m"
      },
      "source": [
        "# Part 4: Sequential Text Represenation\n",
        "\n",
        "In this section, we will find out whether neural representations of our text can help find coreferents.\n",
        "\n",
        "The main idea is to run a bidirectional LSTM model, and use the resulting hidden states to form representations of the markables. These will be fed into a feedforward classifier similar to the one from the previous section, except that the match features will also be embedded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGVcym-JFU2m",
        "outputId": "ee876d48-566b-4a1e-83f3-59ef4cd4f844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3530\n"
          ]
        }
      ],
      "source": [
        "# Preparing the vocabulary for a word-to-index dictionary necessary for the initial embeddings table\n",
        "vocab = set()\n",
        "for doc in all_words + all_words_dev + all_words_test:\n",
        "    vocab.update(doc)\n",
        "vocab = sorted(list(vocab))\n",
        "word_to_ix = {w:i for i,w in enumerate(vocab)}\n",
        "print(len(vocab))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGr-x5IuFU2m"
      },
      "source": [
        "We implement `neural_net.BiLSTMWordEmbedding` as a word embedding lookup table followed by a bi-directional LSTM which runs on a text (here, the entire document) and outputs the hidden state from the LSTM as a contextual embedding for each word in it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "collapsed": true,
        "id": "PxkyJ0YJFU2m"
      },
      "outputs": [],
      "source": [
        "WORD_EMB_DIM = 64\n",
        "WORD_LSTM_EMB_DIM = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIz-sVgBFU2m",
        "outputId": "5209eea3-b84f-4822-881c-bc7a1c841e92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "McDermott International Inc. said its Babcock & Wilcox unit completed the sale of its Bailey Controls Operations ... \n",
            "\n",
            "its \n",
            " tensor([-0.0129, -0.1065,  0.1406, -0.4480, -0.0298], grad_fn=<SliceBackward0>)\n",
            "its \n",
            " tensor([-3.4436e-04, -6.9696e-02,  8.9008e-02, -4.5312e-01, -2.8312e-02],\n",
            "       grad_fn=<SliceBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(1984)\n",
        "word_lstm = neural_net.BiLSTMWordEmbedding(word_to_ix, WORD_EMB_DIM, WORD_LSTM_EMB_DIM, 1, 0.5)\n",
        "embs = word_lstm(all_words[0])\n",
        "print(' '.join(all_words[0][:17] + ['...']), '\\n')\n",
        "print(all_words[0][4], '\\n', embs[4][0][:5])\n",
        "print(all_words[0][13], '\\n', embs[13][0][:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzNMxKMkFU2n"
      },
      "source": [
        "We see how the same word type (*its*) is assigned different embeddings based on its context in the document."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kZZlCFUFU2n"
      },
      "source": [
        "## Attention Model\n",
        "\n",
        "Our markable embeddings will be trained using an **Attention Model** which accepts the embeddings for the words $\\{w_i\\}$ in a markable and outputs a single vector that \"attends\" to the single vectors according to what it believes is their importance.\n",
        "This concept, [originally used](https://arxiv.org/abs/1409.0473) for sequence-to-sequence models such as Machine Translation, is applied for our task as yet another attempt to find the crucial part of a markable, like we did for the head-finding heuristic and for the content-word matching. While those were \"hard\" techniques, yes-or-no for each token, here we're applying a \"soft\" weighting that still assigns all the words in the text some significance.\n",
        "\n",
        "Practically, our model will train a vector parameter of the same embedding size as the BiLSTM output, $\\vec{u}$. Each word's embedding in the input span $\\vec{e_i}$ will be multiplied (dot-product) with $\\vec{u}$ to assign it a scalar weight, $a_i$. Finally each embedding will be multiplied by its normalized (softmaxed) weight $\\alpha_i$, and the sum of these weighted vectors will be our markable's output embedding, $\\vec{e_m}$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRAaU23rFU2n",
        "outputId": "4263bae2-12ff-4a8a-e6bc-508c889608bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['McDermott', 'International', 'Inc.'] set_356 \n",
            " tensor([0.1076, 0.1651, 0.1864], grad_fn=<SliceBackward0>)\n",
            "['its'] set_356 \n",
            " tensor([-0.0129, -0.1065,  0.1406], grad_fn=<SliceBackward0>)\n",
            "['its'] set_357 \n",
            " tensor([-0.0003, -0.0697,  0.0890], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(1984)\n",
        "attn_layer = neural_net.AttentionBasedMarkableEmbedding(WORD_LSTM_EMB_DIM)\n",
        "mark_embs = [attn_layer(embs, m) for m in all_markables[0]]\n",
        "for j in [0, 1, 4]:\n",
        "    print(all_markables[0][j].string, all_markables[0][j].entity, '\\n', mark_embs[j][:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2pcTMLdFU2n"
      },
      "source": [
        "We will score a markable pair based on the following features:\n",
        "\n",
        "1. Each markable's attended embedding\n",
        "1. A low-dimension embedding for each of the pairwise features we've extracted in the previous sections. Since they are boolean, each will have an embedding for its ''false'' state and one for its ''true'' state.\n",
        "\n",
        "First, let's implement a quick extractor for positive-valued features from a mention pair."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "collapsed": true,
        "id": "uK0mpCqJFU2o"
      },
      "outputs": [],
      "source": [
        "def get_positive_feats(doc, i, a, feats=coref_features.minimal_features):\n",
        "    return [k for k,v in feats(doc,i,a).items() if v > 0.0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hizQ6d6mFU2o",
        "outputId": "4f70f47b-d11f-4953-d65a-70e247c32c75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['exact-match', 'last-token-match', 'content-match']"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "get_positive_feats(all_markables[1], 0, 13)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VelX4FfaFU2o"
      },
      "source": [
        "Now we will concatenate all of these embeddings together and use them as input in a two-layer feedforward network (with ReLU nonlinearity) which will produce a scalar score for markable match."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDk47BUAFU2o",
        "outputId": "6ee0c945-bbbc-4886-c557-9d47cdd7dfab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.1786], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "BOOLEAN_FEATURE_DIM = 6\n",
        "SCORER_HIDDEN_DIM = 164\n",
        "\n",
        "# starting with just one document\n",
        "torch.manual_seed(1984)\n",
        "word_lstm1 = neural_net.BiLSTMWordEmbedding(word_to_ix, WORD_EMB_DIM, WORD_LSTM_EMB_DIM, 1, 0.5)\n",
        "embs1 = word_lstm1(all_words[1])\n",
        "attn_layer1 = neural_net.AttentionBasedMarkableEmbedding(WORD_LSTM_EMB_DIM)\n",
        "mkbls1 = all_markables[1]\n",
        "mark_embs1 = [attn_layer(embs1, m) for m in mkbls1]\n",
        "scorer = neural_net.SequentialScorer(WORD_LSTM_EMB_DIM, min_features, BOOLEAN_FEATURE_DIM, SCORER_HIDDEN_DIM)\n",
        "scorer(mark_embs1[13], mark_embs1[0], get_positive_feats(mkbls1, 13, 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DZyAlzxFU2o"
      },
      "source": [
        "We implement `score_instance()` and `instance_top_scores()` in `neural_net.SequentialScorer`. Their purpose is the same as the one in `FFCoref`, but they require the extra embeddings parameter. The former will require some changes to adapt to the different `forward()`, but the latter can be identical to its correlate in `FFCoref` if implemented correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfWePcSSFU2o",
        "outputId": "f3843891-1a8b-4bc2-9ad3-eb16ffc9747f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1786, -0.1996, -0.2356, -0.2084, -0.1870, -0.1862, -0.1949, -0.2230,\n",
              "         -0.2247, -0.2132, -0.2400, -0.1906, -0.2505, -0.2367]],\n",
              "       grad_fn=<CopySlices>)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "scorer.score_instance(mark_embs1, all_markables[1], 13, coref_features.minimal_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkt4IS5pFU2o"
      },
      "source": [
        "Due to the length of our documents and number of parameters, torch may not work properly on the entire text. We'll truncate the files before we train and use only the minimal pairwise feature space, causing our performance to be suboptimal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZZqdzS1FU2o",
        "outputId": "f3adba6d-2001-4921-9747-6134bb2c108a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 complete.\n",
            "Document losses = 0.22043, 0.21534, 0.27164, 0.17878, 0.37294, 0.43248, 0.34747, 0.24185, 0.07921, 0.27637, 0.23786, 0.19303, 0.33230, 0.23462, 0.10123, 0.25696, 0.17396, 0.32398, 0.15706, 0.05580, 0.29033, 0.48275\n",
            "Overall loss = 0.24898\n",
            "Epoch 2 complete.\n",
            "Document losses = 0.30533, 0.04087, 0.11175, 0.19694, 0.37606, 0.43766, 0.36037, 0.23909, 0.10032, 0.22340, 0.24932, 0.19412, 0.28913, 0.23316, 0.08815, 0.26690, 0.18012, 0.29170, 0.17112, 0.05579, 0.28265, 0.46549\n",
            "Overall loss = 0.23227\n",
            "Epoch 3 complete.\n",
            "Document losses = 0.28406, 0.04547, 0.10289, 0.17440, 0.35293, 0.42351, 0.33969, 0.24050, 0.08158, 0.24350, 0.23826, 0.19589, 0.30743, 0.23147, 0.09214, 0.26338, 0.16493, 0.32297, 0.14797, 0.05483, 0.28206, 0.50596\n",
            "Overall loss = 0.22909\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(1984)\n",
        "tr_word_lstm = neural_net.BiLSTMWordEmbedding(word_to_ix, WORD_EMB_DIM, WORD_LSTM_EMB_DIM, 1, 0.2)\n",
        "tr_attn_layer = neural_net.AttentionBasedMarkableEmbedding(WORD_LSTM_EMB_DIM)\n",
        "tr_scorer = neural_net.SequentialScorer(WORD_LSTM_EMB_DIM, min_features, BOOLEAN_FEATURE_DIM, SCORER_HIDDEN_DIM)\n",
        "optimizer = optim.SGD(list(tr_word_lstm.parameters()) + list(tr_attn_layer.parameters()) + list(tr_scorer.parameters()), lr=ETA_0)\n",
        "neural_net.train(tr_word_lstm, tr_attn_layer, tr_scorer,\\\n",
        "                 optimizer, all_words, all_markables, coref_features.minimal_features, word_limit=150, epochs=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcPdAhqeFU2o"
      },
      "source": [
        "Let's evaluate on the entire dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Wip2vgnFU2o",
        "outputId": "b116fae7-cfc0-4074-f221-9b0d017235af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F: 0.5017\tR: 0.5151\tP:0.4890\n"
          ]
        }
      ],
      "source": [
        "tr_resolver = neural_net.evaluate(tr_word_lstm, tr_attn_layer, tr_scorer, all_words, all_markables, coref_features.minimal_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMxZYUroFU2o",
        "outputId": "aed509ba-6aca-4a9d-af50-c20d2c609508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B-Cubed: 0.5514\tCEAF: 0.4597\tMUC: 0.5390\tAverage: 0.5167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/coreference-resolution/library/utils.py:168: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  \"scipy.optimize.linear_sum_assignment instead.\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "coref_metrics(tr_resolver, all_markables);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFg7LrAjFU2o",
        "outputId": "2bc289a0-eb0d-4593-f260-118733d364c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F: 0.5263\tR: 0.5034\tP:0.5515\n"
          ]
        }
      ],
      "source": [
        "dv_resolver = neural_net.evaluate(tr_word_lstm, tr_attn_layer, tr_scorer, all_words_dev, all_markables_dev, coref_features.minimal_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvmV2i2UFU2o",
        "outputId": "6c4a3ac1-af87-4757-c358-9298415cc28d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B-Cubed: 0.5694\tCEAF: 0.4861\tMUC: 0.5544\tAverage: 0.5366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/coreference-resolution/library/utils.py:168: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  \"scipy.optimize.linear_sum_assignment instead.\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "coref_metrics(dv_resolver, all_markables_dev);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTruLJ8qFU2p"
      },
      "source": [
        "## Pretrained Word Embeddings\n",
        "\n",
        "**Deliverable 4.5**\n",
        "Implement `utils.initialize_with_pretrained()`. Start by copying from your implementation in PS3.\n",
        "(0.5 points)\n",
        "\n",
        "* **Test:** `tests\\test_neural_coref.test_pretrain_embeddings_d4_5()`\n",
        "\n",
        "**Note** that there is a new pretrained file in the `data` folder. Although from the same original source, it is trimmed to the vocabulary in our new dataset, so don't use the same file from PS3. In addition to this attribute, it includes a special token called **&lt;UNK&gt;**. You should use its assigned vector to initialize vectors for all unknown words in the dataset.\n",
        "\n",
        "Later, if you're interested in improving your model's performance, you may want to know that there are more special tokens with trained vectors in the data file:\n",
        "* **&lt;S&gt;** signifies the beginning of a sentence.\n",
        "* **&lt;/S&gt;** signifies the end of a sentence.\n",
        "* **&lt;PAD&gt;** is used to pad short sentences (this one probably won't be useful)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "collapsed": true,
        "id": "Y1Q02J6YFU2p"
      },
      "outputs": [],
      "source": [
        "pret_embs = pickle.load(open('data/pretrained-embeds-coref.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHY-d7GYFU2p",
        "outputId": "ef426b64-b822-492a-ec27-3d4c27340ac3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.34177107 -0.1528549  -0.06971747  0.12536518  0.31670848]\n"
          ]
        }
      ],
      "source": [
        "print(pret_embs['Fujitsu'][:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsMagUalFU2p",
        "outputId": "0bab3364-aefe-4160-a3b5-4e1c4ead889e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.2400684   0.0170402  -0.5328812   0.16161029 -0.03450763]\n"
          ]
        }
      ],
      "source": [
        "print(pret_embs['<UNK>'][:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biAUSEKdFU2p",
        "outputId": "a1d65285-7589-4e6f-bf10-bdf030d5a65b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 complete.\n",
            "Document losses = 0.21651, 0.21096, 0.19878, 0.17347, 0.35505, 0.43552, 0.33492, 0.24659, 0.07781, 0.25437, 0.24158, 0.19746, 0.30019, 0.22686, 0.09899, 0.25521, 0.17340, 0.32177, 0.15531, 0.05598, 0.29123, 0.48306\n",
            "Overall loss = 0.24091\n",
            "Epoch 2 complete.\n",
            "Document losses = 0.30625, 0.04299, 0.11356, 0.19089, 0.37243, 0.43567, 0.35710, 0.23797, 0.09520, 0.22210, 0.24407, 0.19255, 0.29286, 0.23245, 0.08275, 0.27424, 0.17821, 0.29517, 0.16738, 0.05564, 0.28156, 0.47456\n",
            "Overall loss = 0.23153\n",
            "Epoch 3 complete.\n",
            "Document losses = 0.28896, 0.04805, 0.10424, 0.16808, 0.34641, 0.42234, 0.33373, 0.23943, 0.07991, 0.23913, 0.23613, 0.19291, 0.30121, 0.23601, 0.07406, 0.28637, 0.17192, 0.29879, 0.16228, 0.05555, 0.28057, 0.47962\n",
            "Overall loss = 0.22706\n",
            "Epoch 4 complete.\n",
            "Document losses = 0.29017, 0.05014, 0.10818, 0.16478, 0.34093, 0.42192, 0.32818, 0.24134, 0.07730, 0.22908, 0.24234, 0.19248, 0.29585, 0.22651, 0.09612, 0.25564, 0.16554, 0.32542, 0.14895, 0.05547, 0.28078, 0.51012\n",
            "Overall loss = 0.22675\n",
            "Epoch 5 complete.\n",
            "Document losses = 0.31542, 0.03509, 0.10118, 0.17746, 0.35718, 0.43791, 0.34404, 0.23715, 0.08577, 0.22365, 0.23874, 0.19298, 0.29664, 0.23405, 0.07761, 0.27917, 0.16997, 0.30050, 0.16054, 0.05549, 0.28082, 0.48275\n",
            "Overall loss = 0.22829\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(1984)\n",
        "tr_pt_word_lstm = neural_net.BiLSTMWordEmbedding(word_to_ix, WORD_EMB_DIM, WORD_LSTM_EMB_DIM, 1, 0.2)\n",
        "utils.initialize_with_pretrained(pret_embs, tr_pt_word_lstm)\n",
        "tr_pt_attn_layer = neural_net.AttentionBasedMarkableEmbedding(WORD_LSTM_EMB_DIM)\n",
        "tr_pt_scorer = neural_net.SequentialScorer(WORD_LSTM_EMB_DIM, min_features, BOOLEAN_FEATURE_DIM, SCORER_HIDDEN_DIM)\n",
        "optimizer = optim.SGD(list(tr_pt_word_lstm.parameters()) + list(tr_pt_attn_layer.parameters()) + list(tr_pt_scorer.parameters()), lr=ETA_0)\n",
        "neural_net.train(tr_pt_word_lstm, tr_pt_attn_layer, tr_pt_scorer,\\\n",
        "                 optimizer, all_words, all_markables, coref_features.minimal_features, word_limit=150, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDevV1SBFU2p",
        "outputId": "006fc109-fc3f-4787-f2c1-27db2adf267f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F: 0.3240\tR: 0.5638\tP:0.2273\n"
          ]
        }
      ],
      "source": [
        "tr_pt_resolver = neural_net.evaluate(tr_pt_word_lstm, tr_pt_attn_layer, tr_pt_scorer, all_words, all_markables, coref_features.minimal_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyLb4B4fFU2p",
        "outputId": "e859260b-1cb2-4b98-c547-fd4b4cabdf9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B-Cubed: 0.1567\tCEAF: 0.1515\tMUC: 0.5113\tAverage: 0.2732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/coreference-resolution/library/utils.py:168: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  \"scipy.optimize.linear_sum_assignment instead.\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "coref_metrics(tr_pt_resolver, all_markables);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDINL-i-FU2p",
        "outputId": "9b20a9c6-95e1-459c-b151-801cf3584ae0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F: 0.3596\tR: 0.5503\tP:0.2671\n",
            "B-Cubed: 0.2098\tCEAF: 0.1831\tMUC: 0.5570\tAverage: 0.3166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/coreference-resolution/library/utils.py:168: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  \"scipy.optimize.linear_sum_assignment instead.\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "tr_pt_resolver_dev = neural_net.evaluate(tr_pt_word_lstm, tr_pt_attn_layer, tr_pt_scorer, all_words_dev, all_markables_dev, coref_features.minimal_features)\n",
        "coref.write_predictions(tr_pt_resolver_dev,\n",
        "                        all_markables_dev,\n",
        "                        'predictions/nn-dev.preds');\n",
        "coref_metrics(tr_pt_resolver_dev, all_markables_dev);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qZB0DsIFU2p"
      },
      "source": [
        "## Part 5: Domain Adaptation\n",
        "\n",
        "Our dataset has a second part, which is a corpus of fairy tales, rather than news stories.\n",
        "\n",
        "Let's take advantage of this setup to see how well our WSJ-trained model does over the fairy tale data, as opposed to a model trained on the fairy tales themselves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "collapsed": true,
        "id": "ba8sSFBuFU2p"
      },
      "outputs": [],
      "source": [
        "ft_dv_dir = os.path.join('data','tales','dev')\n",
        "ft_tr_dir = os.path.join('data','tales','train')\n",
        "ft_te_dir = os.path.join('data','tales','test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "collapsed": true,
        "id": "h572FFXQFU2p"
      },
      "outputs": [],
      "source": [
        "ft_all_markables, ft_all_words = coref.read_dataset(ft_tr_dir, tagger=pos_tag)\n",
        "ft_all_markables_dev, ft_all_words_dev = coref.read_dataset(ft_dv_dir, tagger=pos_tag)\n",
        "ft_all_markables_te, ft_all_words_te = coref.read_dataset(ft_te_dir, tagger=pos_tag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxLmNw0ZFU2p",
        "outputId": "8025de94-45ff-49a0-db10-86273fd6eaea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F: 0.6511\tR: 0.5545\tP:0.7884\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6510840108401084, 0.5545297172533179, 0.7883511074651354)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "coref.eval_on_dataset(exact_matcher, ft_all_markables)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPwoVZjzFU2p"
      },
      "source": [
        "The exact matcher is getting much higher numbers on this dataset than on WSJ. Let's train an ML system and see the differences. We'll use `FFCoref` from section 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nGKXvOWFU2p",
        "outputId": "52fbf6e0-ee5f-444f-9b8d-d0493f414903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss = 0.6305409525087488\n",
            "Loss = 0.602217978526913\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(1984)\n",
        "coref_ff_fairy = coref_learning.FFCoref(min_features_and_distances, 50)\n",
        "optimizer = optim.SGD(coref_ff_fairy.parameters(), lr=ETA_0)\n",
        "coref_learning.train(coref_ff_fairy, optimizer, ft_all_markables, joint_feats, epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8jDvZlpFU2p",
        "outputId": "1694d61d-1512-47d0-a359-1c895215f67d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F: 0.5970\tR: 0.5530\tP:0.6486\n"
          ]
        }
      ],
      "source": [
        "# in-domain trained, tested on fairy tale data\n",
        "coref_learning.evaluate(coref_ff_fairy, ft_all_markables_dev, joint_feats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CPyMgqDFU2p",
        "outputId": "769e1d10-d5c3-4eab-eb4e-7892e4243042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B-Cubed: 0.4960\tCEAF: 0.4550\tMUC: 0.6517\tAverage: 0.5342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/coreference-resolution/library/utils.py:168: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  \"scipy.optimize.linear_sum_assignment instead.\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "ft_ff_matcher = coref_learning.make_resolver(joint_feats, coref_ff_fairy)\n",
        "coref_metrics(ft_ff_matcher, ft_all_markables_dev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbIO1MqpFU2q"
      },
      "source": [
        "These are the **in-domain** dev set scores for the fairy tale dataset.\n",
        "\n",
        "Recall that the in-domain numbers for the WSJ portion were the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_y141qmTFU2q",
        "outputId": "75272dca-aa59-4221-d748-fffe3e860b11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B-Cubed: 0.5702\tCEAF: 0.4859\tMUC: 0.5442\tAverage: 0.5334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/coreference-resolution/library/utils.py:168: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  \"scipy.optimize.linear_sum_assignment instead.\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "coref_metrics(ff_w_dist_matcher, all_markables_dev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtY_Kkh3FU2q"
      },
      "source": [
        "Now we can see how the **cross-domain** results look. Can a model trained on news data be reliably used in a fairy-tale setting? How about the converse?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FGNffVWFU2q",
        "outputId": "d455334f-4a07-4a1f-ee8a-f9a61288993c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B-Cubed: 0.5440\tCEAF: 0.4501\tMUC: 0.5240\tAverage: 0.5060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/coreference-resolution/library/utils.py:168: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  \"scipy.optimize.linear_sum_assignment instead.\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# trained on fairy, tested on WSJ\n",
        "coref_metrics(ft_ff_matcher, all_markables_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBtHNiZNFU2t",
        "outputId": "c10d90f9-996e-4935-8e8b-24b388e7e8a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B-Cubed: 0.5286\tCEAF: 0.4951\tMUC: 0.6807\tAverage: 0.5682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/coreference-resolution/library/utils.py:168: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  \"scipy.optimize.linear_sum_assignment instead.\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# trained on WSJ, tested on fairy\n",
        "coref_metrics(ff_w_dist_matcher, ft_all_markables_dev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCMVSQ1nFU2u"
      },
      "source": [
        "These are lower than in-domain, but surprisingly enough not too low. In other tasks this problem is more acute."
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3.9.12 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    },
    "colab": {
      "name": "coreference_resolution.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UchrsBPYFU2i",
        "t3nM0NDfFU2i",
        "ZkRvjUaPFU2j",
        "5jtiJzy9FU2j",
        "WUYR2_zSFU2k",
        "11PQLcGdFU2m",
        "1kZZlCFUFU2n",
        "aTruLJ8qFU2p",
        "7qZB0DsIFU2p"
      ]
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}